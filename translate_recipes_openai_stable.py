import os
import sys
import json
import time
from openai import OpenAI

# ================================
# CONFIGURATION STABLE
# ================================
MODEL = "gpt-4o-mini"

# On r√©duit la taille des batchs pour moins charger le r√©seau
BATCH_SIZE = 3          # 3 recettes par appel au lieu de 10

# On laisse BEAUCOUP plus de chances au r√©seau
MAX_RETRIES = 10        # jusqu'√† 10 tentatives par batch
TIMEOUT = 60            # chaque appel peut attendre jusqu'√† 60 s

# On ralentit un peu entre chaque batch pour laisser souffler la box
SLEEP_BETWEEN_BATCHES = 1.0

# Pour tester sur un petit nombre au d√©but, tu peux mettre 30
# Quand tu es ok tu remets None pour tout traiter
MAX_RECIPES = None       # ‚Üê commence comme √ßa pour tester

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

SYSTEM_PROMPT = """
Tu es un assistant culinaire pour une application francophone.
R√®gles :
1. Traduire en fran√ßais : nom, description, ingr√©dients, √©tapes, cat√©gories, hashtags.
2. Convertir les unit√©s US -> unit√©s m√©triques fran√ßaises (g, kg, ml, cl, L, c. √† soupe, c. √† caf√©).
3. Corriger l‚Äôorthographe et simplifier le style √† la mani√®re des fiches techniques.
4. Garder exactement la m√™me structure JSON.
5. Toujours renvoyer un TABLEAU JSON propre, sans texte autour.
"""

# ================================
#  FONCTION STABLE OPENAI
# ================================

def openai_safe_call(messages):
    """Appel OpenAI avec retry automatique + timeout."""
    for attempt in range(1, MAX_RETRIES + 1):
        try:
            print(f"   ‚Üí Appel OpenAI (tentative {attempt}/{MAX_RETRIES})...")
            response = client.chat.completions.create(
                model=MODEL,
                messages=messages,
                timeout=TIMEOUT,
            )
            return response.choices[0].message.content.strip()

        except Exception as e:
            print(f"      ‚ö†Ô∏è Erreur r√©seau : {str(e)[:80]}")
            if attempt == MAX_RETRIES:
                print("      ‚ùå Abandon : trop d'√©checs sur ce batch.")
                return None
            wait = attempt * 2
            print(f"      ‚è≥ On r√©essaie dans {wait} sec...")
            time.sleep(wait)

    return None


# ================================
#  TRAITEMENT DES BATCHS
# ================================

def process_batch(batch, batch_idx, total_batches):
    print(f"\n=== Batch {batch_idx+1}/{total_batches} (taille : {len(batch)}) ===")

    messages = [
        {"role": "system", "content": SYSTEM_PROMPT},
        {
            "role": "user",
            "content": (
                "Voici un TABLEAU JSON de recettes. "
                "Renvoie le m√™me tableau, traduit et corrig√©.\n\n"
                + json.dumps(batch, ensure_ascii=False)
            ),
        },
    ]

    content = openai_safe_call(messages)
    if not content:
        print("‚ö†Ô∏è Batch conserv√© tel quel (pas de r√©ponse)")
        return batch

    try:
        parsed = json.loads(content)
        if isinstance(parsed, list) and len(parsed) == len(batch):
            print("‚úÖ Batch trait√© avec succ√®s.")
            return parsed
        else:
            print("‚ö†Ô∏è Format inattendu ‚Üí batch conserv√©")
            return batch
    except Exception:
        print("‚ö†Ô∏è JSON invalide ‚Üí batch conserv√©")
        return batch


# ================================
#  MAIN
# ================================

def main():
    if len(sys.argv) < 3:
        print("Usage : python translate_recipes_openai_stable.py fichier.json fr")
        return

    input_file = sys.argv[1]
    if not os.path.exists(input_file):
        print("Fichier introuvable :", input_file)
        return

    print("üìÇ Chargement :", input_file)
    with open(input_file, "r", encoding="utf-8") as f:
        data = json.load(f)

    if MAX_RECIPES:
        data = data[:MAX_RECIPES]

    total = len(data)
    print("üîÑ Nombre total de recettes :", total)

    output = []
    num_batches = (total + BATCH_SIZE - 1) // BATCH_SIZE

    for i in range(num_batches):
        start = i * BATCH_SIZE
        end = min(start + BATCH_SIZE, total)
        batch = data[start:end]

        new_batch = process_batch(batch, i, num_batches)
        output.extend(new_batch)

        # Sauvegarde de s√©curit√©
        if (i + 1) % 3 == 0:
            tmp_name = f"intermediate_batch_{i+1}.json"
            with open(tmp_name, "w", encoding="utf-8") as tmp:
                json.dump(output, tmp, ensure_ascii=False, indent=2)
            print(f"üíæ Sauvegarde interm√©diaire : {tmp_name}")

        time.sleep(SLEEP_BETWEEN_BATCHES)

    out_file = "translated_openai_stable_fr.json"
    with open(out_file, "w", encoding="utf-8") as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print("\nüéâ TRADUCTION TERMIN√âE ‚úîÔ∏è")
    print("üìÅ Fichier final :", out_file)


if __name__ == "__main__":
    main()
