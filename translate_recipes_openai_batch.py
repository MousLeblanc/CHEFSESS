import os
import sys
import json
import time
from openai import OpenAI

# -----------------------------------------
# CONFIG
# -----------------------------------------
MODEL = "gpt-4o-mini"
BATCH_SIZE = 10       # nombre de recettes par appel
SLEEP_BETWEEN_CALLS = 0.2
MAX_RECIPES = 50   # ex: 100 pour tester, None pour tout

client = OpenAI(
    api_key=os.environ.get("OPENAI_API_KEY")
)

SYSTEM_PROMPT = """
Tu es un assistant culinaire pour une application de restauration collective fran√ßaise.

On va t'envoyer un TABLEAU JSON de plusieurs recettes (format Chef SES).
Tu dois renvoyer un TABLEAU JSON de M√äME LONGUEUR, dans le m√™me ordre,
avec les r√®gles suivantes :

1. Tout le texte doit √™tre en fran√ßais correct :
   - name, description
   - ingredients[i].name
   - preparationSteps[i]
   - category, hashtags, tags, diet, pathologies

2. Convertir les unit√©s US en unit√©s m√©triques fran√ßaises :
   - tsp/teaspoon  ‚Üí c. √† caf√© (~5 ml)
   - tbsp/tablespoon ‚Üí c. √† soupe (~15 ml)
   - cup ‚Üí ~240 ml (liquides) ou ~120‚Äì140 g (secs, adapte selon l‚Äôingr√©dient)
   - oz (poids) ‚Üí ~28 g
   - lb ‚Üí ~450 g
   N‚Äôutiliser que : g, kg, ml, cl, dl, L, c. √† caf√©, c. √† soupe, pi√®ce(s).
   Ajuster les QUANTIT√âS en cons√©quence, avec des valeurs r√©alistes.

3. Corriger l‚Äôorthographe et la grammaire en fran√ßais, style fiche technique simple.

4. NE PAS changer la structure JSON :
   - m√™mes cl√©s, m√™mes types.
   - garder tous les champs non textuels (id, nutriments, etc.) sauf unit√©s/quantit√©s adapt√©es.

5. SORTIE :
   - Renvoie UNIQUEMENT un TABLEAU JSON valide
     (par ex. [ {...}, {...}, ... ]).
   - Pas de texte explicatif autour.
"""

def process_batch(batch, batch_index, total_batches):
    """Traite un batch (liste de recettes) avec l'API."""
    print(f"\n=== Batch {batch_index+1}/{total_batches} | {len(batch)} recettes ===")

    user_prompt = (
        "Voici un TABLEAU JSON de recettes. Applique toutes les r√®gles et renvoie un TABLEAU JSON de m√™me longueur.\n\n"
        + json.dumps(batch, ensure_ascii=False, indent=2)
    )

    try:
        response = client.chat.completions.create(
            model=MODEL,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": user_prompt},
            ],
            temperature=0.2,
            timeout=90,
        )
        content = response.choices[0].message.content.strip()
        new_batch = json.loads(content)

        if not isinstance(new_batch, list) or len(new_batch) != len(batch):
            print("‚ö†Ô∏è R√©ponse inattendue de l‚ÄôAPI (longueur diff√©rente). Batch conserv√© tel quel.")
            return batch

        print("‚úÖ Batch trait√© avec succ√®s.")
        return new_batch

    except Exception as e:
        print("‚ö†Ô∏è Erreur sur ce batch, on garde les recettes originales. D√©tail :", e)
        return batch


def main():
    if len(sys.argv) < 3:
        print("Usage: python translate_recipes_openai_batch.py <input.json> fr")
        return

    input_file = sys.argv[1]
    target_lang = sys.argv[2]

    if not os.path.exists(input_file):
        print("Fichier introuvable :", input_file)
        return

    print("üìÇ Chargement du fichier :", input_file)
    with open(input_file, "r", encoding="utf-8") as f:
        data = json.load(f)

    if not isinstance(data, list):
        print("Le fichier doit contenir une LISTE de recettes.")
        return

    if MAX_RECIPES is not None:
        data = data[:MAX_RECIPES]

    total_recipes = len(data)
    print(f"üîÑ Nombre de recettes √† traiter : {total_recipes}")

    output = []
    total_batches = (total_recipes + BATCH_SIZE - 1) // BATCH_SIZE

    for b_index in range(total_batches):
        start = b_index * BATCH_SIZE
        end = min(start + BATCH_SIZE, total_recipes)
        batch = data[start:end]

        print(f"\n--- Traitement des recettes {start+1} √† {end} ---")
        new_batch = process_batch(batch, b_index, total_batches)
        output.extend(new_batch)

        # Sauvegarde interm√©diaire
        if (b_index + 1) % 5 == 0:
            tmp_name = f"translated_batch_partial_{b_index+1}.json"
            with open(tmp_name, "w", encoding="utf-8") as tmp:
                json.dump(output, tmp, ensure_ascii=False, indent=2)
            print(f"üíæ Sauvegarde interm√©diaire : {tmp_name}")

        time.sleep(SLEEP_BETWEEN_CALLS)

    output_file = "translated_openai_batch_fr.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print("\nüéâ TRAVAIL TERMIN√â !")
    print("üìÅ Fichier final :", output_file)


if __name__ == "__main__":
    main()
